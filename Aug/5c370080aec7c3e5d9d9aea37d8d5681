Authorities in Germany working to identify and combat child pornography on the internet may soon have a powerful new tool at their disposal: artificial intelligence. Peter Biesenbach, the minister of justice in North Rhine-Westphalia, Germany's largest state, announced on Monday a new project in cooperation with computer giant Microsoft: The development of new artificial intelligence (AI) technology that would not only automize the detection of child pornography on the internet, but also lighten the workload and psychological burden on authorities dealing with such disturbing content. "Artificial intelligence will be able to handle huge amounts of data in a short space of time and will not have mental stress issues," Biesenbach said in a press conference Monday. "Human intelligence and analog work will then be used for other investigative measures, such as the execution of pending search warrants, thus strengthening law enforcement as a whole." State Premier Armin Laschet took to Twitter to applaud the "first nationwide use of artificial intelligence" in his state. "Child pornography is one of the most heinous crimes," he wrote. "Here, too, we have zero tolerance for criminals." A growing problem German authorities note they have long faced difficulties halting huge amounts of child pornography from circulating on the internet. That's due to the sophistication of encryption techniques used by perpetrators, a dearth of qualified staff to sift through suspected cases, and hesitance in Germany to implement new AI before the technology's legal implications have been vetted. Read more: Artificial intelligence: Are machines taking over? As of mid-June, there were just under 1,900 open cases of suspected child abuse or pornography in North Rhine-Westphalia, according to information from the state's Ministry of Justice. Of those cases, experts have only evaluated 228 and there are still over 500 search warrants waiting to be greenlit. Moreover, only 104 experts in North Rhine-Westphalia are tasked with assessing suspected cases of child pornography on the internet, even though state authorities estimate that some 3 million gigabytes of data need to be analyzed. On average, an analyst can only work through 500 pictures every hour. "These numbers clearly show that investigators aren't managing to master these huge amounts of data," Herbert Reul, interior minister of North Rhine-Westphalia, told reporters in June when he announced a slate of modernization initiatives for special investigators, including exploring new AI technologies and bolstering police staff. That same month, Germany's Federal Crime Office (BKA) reported 7,449 cases of the production and distribution of child pornography in 2018, a 14% increase over 2017. International cooperation had much to do with uncovering such cases, the BKA elaborated. New solutions Microsoft pegged its cooperation with North Rhine-Westphalia on Monday as a "globally unique process" to analyze, encrypt and prosecute cases of child pornography. Over the coming year, the algorithm will be trained with criminally relevant images to accurately recognize suspected child pornography, according to information from Microsoft. It would anonymize and deconstruct pictures to ensure that the identities of both perpetrator and victim don't fall into the wrong hands and house all imagery in a cloud-based server. Authorities would then proof whether the algorithm's selections are criminally relevant, combining human expertise with new technology to expedite criminal procedures and lighten the psychological burden on investigators. No other AI algorithms are currently in use in Germany to fight criminality, Ralf Herrenbrück, a spokesman for North Rhine-Westphalia's Ministry of Justice, told DW. The ministry hopes to put the algorithm into practice within the next calendar year, he added. Artificial intelligence is booming in China, but often at the cost of human rights and democratic values, experts warn Right path One could view Germany as behind other nations like the United States and China in the application of AI — from cybercrime to education and healthcare, Tyson Barker, Transatlantic and Digital Program Director with the Aspen Institute Germany, told DW. But Germany is "well-served" in practicing a bit of caution, he said: The societal implications of AI technologies — such as privacy concerns, government abuse and the erosion of democratic values — are being discovered in real-time around the world. Without a national framework for AI development and implementation that protects democratic values, nations like the US and China "are changing the tires on the car as it's moving," he said. A 2016 investigative report by ProPublica revealed racial bias in AI algorithms for analyzing whether inmates should be eligible for parole in the United States. Meanwhile, a report by The New York Times uncovered Chinese efforts to use AI to identify and intern members of minority groups. "These things are still in experimental phases," said Barker. While AI allows "you to drill through the layers of encrypted [child pornography] much more easily… there has to be humans in the loop, as well as a sophisticated judicial process between the courts and the executive." "Once that's in place, you'll have the basis to do something in Germany," he added. 