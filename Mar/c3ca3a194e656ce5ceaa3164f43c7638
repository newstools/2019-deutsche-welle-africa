A growing number of former tech employees, politicians, academics and activists are seeking to raise awareness about the negative consequences of social media consumption and are advocating for greater thoughtfulness regarding the creation and implementation of tech. One of the leading voices of the 'thoughtful tech' movement is David Ryan Polgar, a self-proclaimed 'tech ethicist' and digital citizenship expert who explores the evolving relationship with technology from an ethical, legal and emotional perspective. At the TechChill conference in Riga, Latvia last month, DW spoke with Polgar about his hopes and goals for the thoughtful tech movement. *** DW: How would you summarize the "thoughtful tech movement," as you call it? David Ryan Polgar: It is generally in the sphere of the attention economy and the kind of dopamine issue we're having. We've seen the promise of social media and emerging technology — but we've also seen the peril of what happens when it is unfettered and unrestrained. I think most people, myself included, have come to the realization that since we're spending so much time online, it should better our well-being and give us joy. Oftentimes, however, the incentives for social media companies might be more aligned with engagement, which is not directly related to enjoyment. We need to focus on enjoyment as opposed to engagement, and transition from Facebook's old mantra of 'move fast and break things' to 'move thoughtfully and fix things.' That is going to mean a massive undertaking with a change in the business model as well. How do you propose tech companies do that, especially given that their recommendation algorithms are designed to maximize the time people spend on their site and arguably make them addicted? And how exactly does the business model need to change? Many people wrongly assume that social media companies will make their products less addictive, if you will, by putting public pressure on them. They operate in a highly competitive market with shareholders telling them to maximize their profits. We should focus more on what's going to change the business model. Right now, social media companies do financially good by doing something that is bad on a user level. YouTube is a prime example. It puts its blinders on and asks: 'What's going to get the most engagement?' All too often, the answer is salacious content, including misinformation and conspiracy theories — things counter to what is good for users and society. We need to make it where YouTube makes the most money by maximizing user enjoyment, and we can align that by changing the financial incentives. Imagine I had a trampoline park allowing children to go extremely high up in the air. Kids might love it, and parents might pay for it, but I still wouldn't build these kind of dangerous trampolines because the threat of a lawsuit would offset the benefits. Likewise, social media companies will change their business model when they face significant fines for misinforming the public. That's why Germany's internet hate speech law [NetzDG] is a step in the right direction. In the US, Facebook may face a multi-billion dollar fine over privacy lapses. When misinformation has a large penalty associated with it, companies will try to limit it to maximize their profits. Tech companies had been very loosely regulated until very recently, and that has allowed perverse incentives for behavior that's good for the bottom line but bad for society. Are you suggesting the focus should be on the regulatory side? We need all hands on deck. Regulation definitely matters — politicians and political bodies tend to be better informed and more potentially proactive. But we also need an industry that accepts its massive social responsibility; then you have tech workers, who are realizing they have authority to determine how the products they make are designed. We've already seen examples like last year's walkout over Google's DragonFly project. That's a positive direction. The fourth ingredient is digital citizenship: Users becoming savvier with understanding the technology they use. Finally, we need the media to be involved, for it plays an extremely strong, positive role in educating the general public. However, it needs to have a certain level of understanding and a better relationship with technologists to ensure it can accurately describe some of these issues. These five ingredients — regulation, industry, employees, users and media — will hopefully change the incentives and force companies to do the right thing. Tech ethicist David Ryan Polgar speaking at the TechChill conference in Riga, Latvia in February Do you think initiatives like Apple's Screen Time, which allows users to monitor the time they spend on their phones, are by and large damage control and appeasement policy? Or do they symbolize a real change in mindset? Some skepticism is certainly warranted, but I do think tech companies have a genuine interest in a real change. Most people in tech want to make the world a better place. That's very optimistic, but it's important because if the perception of what they are doing has gone from 'I'm inspired by who we are and what we're doing' to now feeling like they are addicting people, they're not proud of their job anymore. That's a major incentive for tech companies to say: 'We want to be on the right side of history.' Even somebody like Mark Zuckerberg, who could buy anything with the billions of dollars he has amassed, wants history to remember him in a positive light. But that's only going to happen if Facebook will become a benefit to society at large. In February, a UK report on misinformation labelled Facebook executives "digital gangsters." Facebook said it was "open to meaningful regulation," but how much power will it actually be willing to concede? In other words, what will Facebook look like ten years from now? First off, I think the conversation needs to mature to a point where politicians, tech industry and the media reach the conclusion that these issues are incredibly important, but that they are also incredibly complicated. Much of the discussion has been too simplified, in the sense of saying: 'Facebook, fix this problem.' Facebook knows it can't fix this problem without help, so we need less finger pointing and more of 'we've accepted that companies have made massive mistakes; now, let's find out how we can truly improve this.' We're going to have to work together to a certain extent, but that's precisely the tricky part. If we're looking ten years into the future, I agree with Zuckerberg announcing a Supreme Court-like body for Facebook. I think every country is going to have an ombudsman type of character, essentially a liaison with the company to make sure they are doing the right thing. This could look similar to how influential electricity and water companies are treated in the US, where there's a tremendous amount of oversight to prevent these companies from jacking up prices. Ten years from now, we may have some type of ability to vote Zuckerberg and his peers out of office. It might sound extreme right now, but I really do think social media is supplanting our traditional structure of how we relate to governments; at some point, the general public will demand to have a say in how tech companies treat them. In other words, having a public square inside a publicly traded company, as you described it in your talk? Absolutely, yes. Mozilla is a good example. It has a unique structure with a non-profit and a for-profit wing. The non-profit Mozilla Foundation actually owns the for-profit Mozilla Corporation as a single shareholder. This means they can determine whether the company is aligned with its values — precisely what purely for-profit tech companies have struggled with: They might have values they deeply believe in, but the financial incentives to make the most money are extremely strong, not the least because tech is incredibly competitive. A lot of people inside some of these large tech companies I've talked to argue that social media companies ought to be more of a public utility. Even Twitter, which has always struggled with profitability, offers a tremendous amount of potential utility, provided it can deal with issues like misinformation and hate speech. What needs to happen on the user side now that the thoughtful tech movement has raised considerable public awareness? Users need to be savvier: We need to transition from the reactive state to the reflective state. If you take a closer look at our relationship with social media consumption and technology in general, the major problem is our inability to use it 'correctly;' we just put out a lot of crap online. But I think we are starting to become more thoughtful and intentional. I personally advocate for the mental food plate, which is analogous to our food consumption. It has four quadrants: mindful consumption, reflection, brain training and mental assessment. Moreover, I believe the solution isn't necessarily to unplug, but to not be over-plugged. Instead of caring about how often we use a smartphone, we should care about whether the phone is adding to our lives or taking away from it. Are we able to have a conversation with somebody across the table? Are we happy as a person? We need to consider more of how we can incorporate tech into our environment in healthy ways. How can tech companies be more responsible when it comes to social media consumption? To use the food industry analogy again, we have been educated about our consumption with nutritional labels and other measures. So what could a nutritional label for tech look like? One thing we are seeing is if tech has a negative externality of maybe causing issues of misinformation or addictive behavior, we might view it as a responsibility of the tech company to fund a certain amount to media literacy education. That's what happened to the alcohol and cigarette companies, which have to fund anti-smoking campaigns. Technology companies might not fund anti-tech campaigns, but I believe they have a responsibility to have ads about effects on user health and their societal impact at large. What does it mean to be human in the digital age? We need to use social media and technology to maximize our human existence. On a personal level, we need to ask ourselves whether our use of tech is working against us. Is it making us feel alienated, or maybe weakening our personal connections as opposed to deepening them? Then our relationship with technology needs to become more intentional. The great irony of the digital age is that it has caused us to reflect more about what it means to be human, to the extent that it's causing an existential crisis; it's prompting us to ask ourselves: 'Do I have free will, or am I predictable?' This interview has been edited and condensed for clarity.